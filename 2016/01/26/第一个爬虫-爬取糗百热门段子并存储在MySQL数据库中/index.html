
<!DOCTYPE html>
<html lang="en">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="BinHan的博客">
    <title>第一个爬虫-爬取糗百热门段子并存储在 MySQL 数据库中 - BinHan的博客</title>
    <meta name="author" content="Bin Han">
    
    
        <link rel="icon" href="https://ooo.0o0.ooo/2017/07/02/595891293dadc.png">
    
    
        <link rel="alternate" type="application/atom+xml" title="RSS" href="/atom.xml">
    
    <script type="application/ld+json">{"@context":"http://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Bin Han","sameAs":["https://github.com/binhandev","https://weibo.com/u/3172823713"],"image":"https://ooo.0o0.ooo/2017/07/02/595891293dadc.png"},"articleBody":"创建项目主要为爬取糗事百科上热门段子资源，在Terminal下执行命令，参数为项目名。\n1scrapy startproject qiubai\n项目目录结构说明1234567qiubai/\tqiubai/\t\t__init__.py\t\titems.py\t  //项目的items文件\t\tpipelines.py  \t//项目的pipelines文件\t\tsettings\t  //项目的设置文件\tscrapy.cfg\t\t  //项目的配置文件\n\n明确目标，定义 item在 Scrapy 中，items 是用来加载抓取内容的容器，有点类似 iOS 中的 model 模型，可以理解成类似于 ORM 的映射关系，但是提供了一些额外的保护减少错误。\n在qiubai目录下的 items.py 文件，在后面添加我们自己的 class hotItem，包含了头像、昵称、内容、点赞数量及评论数：\n123456789import scrapyclass hotItem(scrapy.Item):    # define the fields for your item here like:    avatar = scrapy.Field()    nickname = scrapy.Field()    content = scrapy.Field()    like = scrapy.Field()    commentNum = scrapy.Field()\n制作爬虫Spider 是用户自己编写的类，用来从一个域（或域组）中抓取信息。他们定义了用于下载的URL列表、跟踪链接的方案、解析网页内容的方式，以此来提取 items。要建立一个 Spider，你必须用 scrapy.spider.BaseSpider 创建一个子类，并确定三个强制的属性：\n\nname：爬虫的识别名称，必须是唯一的，在不同的爬虫中你必须定义不同的名字。\nstart_urls：爬取的URL列表。爬虫从这里开始抓取数据，所以，第一次下载的数据将会从这些 urls 开始。其他子 URL 将会从这些起始URL中继承性生成。\nparse()：解析的方法，调用的时候传入从每一个 URL 传回的 Response 对象作为唯一参数，负责解析并匹配抓取的数据(解析为 item )，跟踪更多的 URL。\n\n接下来定义 Spider，在项目的 /qiubai/spoders 目录下，并设置了 spider 的名字、爬虫的约束范围，及网页文件进行存储\n123456789101112131415import scrapyclass qiubaiSpider(scrapy.spiders.Spider):    name = \"hot\"    allowed_domains = [\"qiushibaike.com/\"]    start_urls = [        \"http://www.qiushibaike.com/hot/page/1\",        \"http://www.qiushibaike.com/hot/page/2\"    ]    def parse(self, response):        filename = response.url.split(\"/\")[-1]        print(filename)        with open(filename, 'wb') as f:            f.write(response.body)\n爬执行爬虫文件\n1scrapy crawl hot\n我这里遇到了下面的的问题，导致抓取失败。\n122016-01-07 17:24:03 [scrapy] DEBUG: Gave up retrying &lt;GET http://www.qiushibaike.com/hot/page/1&gt; (failed 3 times): [&lt;twisted.python.failure.Failure &lt;class &apos;twisted.internet.error.ConnectionDone&apos;&gt;&gt;]2016-01-07 17:24:03 [scrapy] ERROR: Error downloading &lt;GET http://www.qiushibaike.com/hot/page/2&gt;: [&lt;twisted.python.failure.Failure &lt;class &apos;twisted.internet.error.ConnectionDone&apos;&gt;&gt;]\n其实之前是爬的韩寒的新浪博客，并且成功爬了下来。替换成糗百后才才出现了上面的错误，所以我猜想是不是糗百对user-agent进行了限制，所以开始为scrapy爬虫添加随机UA：\n1、在settings.py中添加以下代码，注意修改对应自己的项目名称\n12345DOWNLOADER_MIDDLEWARES = &#123;\t'qiubai.random_user_agent.RandomUserAgentMiddleware': 400,\t'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,&#125;\n1234567891011121314151617181920212223242526272829303132333435363738#!/usr/bin/python#-*-coding:utf-8-*-import randomfrom scrapy.downloadermiddlewares.useragent import UserAgentMiddlewareclass RandomUserAgentMiddleware(UserAgentMiddleware):    def __init__(self, user_agent=''):        self.user_agent = user_agent    def process_request(self, request, spider):        #这句话用于随机选择user-agent        ua = random.choice(self.user_agent_list)        if ua:            request.headers.setdefault('User-Agent', ua)    #the default user_agent_list composes chrome,I E,firefox,Mozilla,opera,netscape    #for more user agent strings,you can find it in http://www.useragentstring.com/pages/useragentstring.php    user_agent_list = [\\        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\"\\        \"Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11\",\\        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6\",\\        \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6\",\\        \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1\",\\        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5\",\\        \"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5\",\\        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\\        \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\\        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",\\        \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3\",\\        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3\",\\        \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\\        \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\\        \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",\\        \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3\",\\        \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24\",\\        \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24\"       ]\n添加完成之后，再次执行就OK了。可以在项目根目录下看到1和2两个文件，其实里面的内容是html源代码，当然这仅仅是演示爬取的过程，接下来就是对源码进行解析。\n以上这个过程主要是我们将使用创建的爬虫 hot，把 start_urls 里指定的每个URL创建了一个 scrapy.http.Request 对象 ，并将爬虫的 parse 方法指定为回调函数，在这里我们仅仅进行了保存操作。然后，这些 Request 被调度并执行，之后通过 parse() 方法返回 scrapy.http.Response 对象，并反馈给爬虫。\n取在基础的爬虫里，这一步可以用正则表达式来抓。在 Scrapy 里，使用一种叫做 XPath selectors的机制，它基于 XPath 表达式。如果你想了解更多 selectors 和其他机制你可以查阅资料：选择器(Selectors)\n简单的罗列一下有用的xpath路径表达式：1234567    表达式\t      描述nodename\t选取此节点的所有子节点。\t/\t\t\t从根节点选取。\t// \t\t\t从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置。\t.\t\t\t选取当前节点。\t..\t\t\t选取当前节点的父节点。\t@\t\t\t选取属性。\n下面是一些 XPath 表达式的例子和他们的含义：\n//div[@class=”stats”]: 选择所有包含 class=”stats” 属性的div 标签元素\n//td: 选择所有  元素\n/title/text(): 选择前面提到的 元素下面的文本内容\n\n接下来我们将对应的源码标签解析，并将对象保存在 items 列表中，对象保存段子的作者昵称头像等内容，我们主要解析的就是下面这段内容：\n\n修改我们的Spider中的解析逻辑：\nimport scrapy\nfrom scrapy.selector import Selector  \nfrom qiubai.items import hotItem\n\nclass qiubaiSpider(scrapy.spiders.Spider):\n    name = \"hot\"\n    allowed_domains = [\"qiushibaike.com/\"]\n    start_urls = [\n        \"http://www.qiushibaike.com/hot/page/1\",\n        \"http://www.qiushibaike.com/hot/page/2\"\n    ]\n\n    def parse(self, response):\n        sel = Selector(response) \n        sites = sel.xpath('//div[@class=\"article block untagged mb15\"]')\n        items = []\n        for site in sites:\n            item = hotItem()\n            userSites = site.xpath('div[@class=\"author clearfix\"]//a')\n            # 有些时候此标签并不一定存在，需要进行判断\n            if userSites:\n                item[\"avatar\"] = userSites[0].xpath('img/@src').extract()\n                item[\"nickname\"] = userSites[1].xpath('h2/text()').extract()\n            item[\"content\"] = site.xpath('div[@class=\"content\"]/text()').extract()\n            num = site.xpath('div[@class=\"stats\"]//i')\n            item[\"like\"] = num[0].xpath(\"text()\").extract()\n            item[\"commentNum\"] = num[1].xpath(\"text()\").extract()\n            items.append(item)\n        return items\n\n存储爬取的内容保存信息的最简单的方法是通过 Feed exports，主要有四种数据格式：JSON，JSON lines，CSV，XML。我们将结果用最常用的 JSON 导出，命令如下：\n-o 后面是导出文件名，-t 后面是导出类型。\nscrapy crawl hot -o items.json -t json\n此时就可以在项目跟目录下看到 items.json 文件，可以使用文本编辑器查看了。当然我们更多的时候还是希望保存到 MySQL中便于使用，这时候就需要使用到 pipelines.py 文件了。\n当然还需要修改 setting.py 这个文件：将下面这句话加进去\nITEM_PIPELINES=[&apos;fjsen.pipelines.QiubaiPipeline&apos;]\n并且修改在 pipelines.py 文件，修改对应的数据库账户密码，建议制定为 utf8 编码，否则会出现乱码。并且推荐使用这种方法进行数据插入，写 sql 语句出错太难调了。\nfrom scrapy import log\nfrom twisted.enterprise import adbapi\nimport MySQLdb\nimport MySQLdb.cursors\n\nclass QiubaiPipeline(object):\n\n    def __init__(self):\n        self.dbpool = adbapi.ConnectionPool('MySQLdb', db='qiubaiDB',\n                user='root', passwd='111111', cursorclass = MySQLdb.cursors.DictCursor,\n                charset='utf8', use_unicode=True)\n\n    def process_item(self, item, spider):\n        # run db query in thread pool\n        query = self.dbpool.runInteraction(self._conditional_insert, item)\n        query.addErrback(self.handle_error)\n        return item\n\n    def _conditional_insert(self, tx, item):\n        # create record if doesn't exist.\n        # all this block run on it's own thread\n        isExist =tx.execute('select *from information_schema.tables where table_name = \"hot\"')\n        if isExist:\n            sql = \"INSERT INTO hot(hot_avatar, hot_nickname, hot_content, hot_like, hot_commentNum) VALUES (%s, %s, %s, %s, %s)\"\n            avatar = item[\"avatar\"]\n            param = \"\"\n            # 需要判断头像昵称是否真的存在，当然这个判断条件写的比较简单\n            if avatar:\n                param = (item['avatar'][0], item[\"nickname\"][0], item['content'][0], int(item['like'][0]), int(item['commentNum'][0]))\n            else:\n                param = (\"\", \"\", item['content'][0], int(item['like'][0]), int(item['commentNum'][0]))\n            tx.execute(sql, param)\n        else:\n            # 如果表不存在则创建\n            tx.execute('create table hot(hot_id INT AUTO_INCREMENT PRIMARY KEY, hot_avatar VARCHAR(100) , hot_nickname VARCHAR(100) , hot_content text NOT NULL, hot_like INT NOT NULL,hot_commentNum INT NOT NULL) DEFAULT CHARSET=utf8')\n\n    def handle_error(self, e):\n        log.err(e)\n\n接着，执行爬虫命令后查看数据库就可以了，在此之前确保你的 MySQL 服务是启动的：\n\n","dateCreated":"2016-01-26T15:20:00+08:00","dateModified":"2017-07-18T21:45:32+08:00","datePublished":"2016-01-26T15:20:00+08:00","description":"创建项目主要为爬取糗事百科上热门段子资源，在Terminal下执行命令，参数为项目名。\n1scrapy startproject qiubai\n项目目录结构说明1234567qiubai/\tqiubai/\t\t__init__.py\t\titems.py\t  //项目的items文件\t\tpipelines.py  \t//项目的pipelines文件\t\tsettings\t  //项目的设置文件\tscrapy.cfg\t\t  //项目的配置文件","headline":"第一个爬虫-爬取糗百热门段子并存储在 MySQL 数据库中","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://binhandev.github.io/2016/01/26/第一个爬虫-爬取糗百热门段子并存储在MySQL数据库中/"},"publisher":{"@type":"Organization","name":"Bin Han","sameAs":["https://github.com/binhandev","https://weibo.com/u/3172823713"],"image":"https://ooo.0o0.ooo/2017/07/02/595891293dadc.png","logo":{"@type":"ImageObject","url":"https://ooo.0o0.ooo/2017/07/02/595891293dadc.png"}},"url":"https://binhandev.github.io/2016/01/26/第一个爬虫-爬取糗百热门段子并存储在MySQL数据库中/","keywords":"Python, Scrapy"}</script>
    <meta name="description" content="创建项目主要为爬取糗事百科上热门段子资源，在Terminal下执行命令，参数为项目名。 1scrapy startproject qiubai 项目目录结构说明1234567qiubai/	qiubai/		__init__.py		items.py	  //项目的items文件		pipelines.py  	//项目的pipelines文件		settings	  //项目的设置文件	scra">
<meta name="keywords" content="Python,Scrapy">
<meta property="og:type" content="blog">
<meta property="og:title" content="第一个爬虫-爬取糗百热门段子并存储在 MySQL 数据库中">
<meta property="og:url" content="https://binhandev.github.io/2016/01/26/第一个爬虫-爬取糗百热门段子并存储在MySQL数据库中/index.html">
<meta property="og:site_name" content="BinHan的博客">
<meta property="og:description" content="创建项目主要为爬取糗事百科上热门段子资源，在Terminal下执行命令，参数为项目名。 1scrapy startproject qiubai 项目目录结构说明1234567qiubai/	qiubai/		__init__.py		items.py	  //项目的items文件		pipelines.py  	//项目的pipelines文件		settings	  //项目的设置文件	scra">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://binhandev.github.io/assets/blogImg/qiubai_1.png">
<meta property="og:image" content="https://binhandev.github.io/assets/blogImg/qiubai_2.png">
<meta property="og:updated_time" content="2017-07-18T13:45:32.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="第一个爬虫-爬取糗百热门段子并存储在 MySQL 数据库中">
<meta name="twitter:description" content="创建项目主要为爬取糗事百科上热门段子资源，在Terminal下执行命令，参数为项目名。 1scrapy startproject qiubai 项目目录结构说明1234567qiubai/	qiubai/		__init__.py		items.py	  //项目的items文件		pipelines.py  	//项目的pipelines文件		settings	  //项目的设置文件	scra">
<meta name="twitter:image" content="https://binhandev.github.io/assets/blogImg/qiubai_1.png">
    
    
        
    
    
        <meta property="og:image" content="https://ooo.0o0.ooo/2017/07/02/595891293dadc.png"/>
    
    
    
    
    <!--STYLES-->
    <link rel="stylesheet" href="/assets/css/style-1udptkpril81ozu8ifd8zpujn7ipu7lefxsiu5gxx0dpnzntdx6dusvki3ao.min.css">
    <!--STYLES END-->
    

    
    <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?72a43f313d40f786cbe746db1a6574ec";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="4">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a class="header-title-link" href="/ ">BinHan的博客</a>
    </div>
    
        
            <a  class="header-right-picture "
                href="#about">
        
        
            <img class="header-picture" src="https://ooo.0o0.ooo/2017/07/02/595891293dadc.png" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="4">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a href="/#about">
                    <img class="sidebar-profile-picture" src="https://ooo.0o0.ooo/2017/07/02/595891293dadc.png" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">Bin Han</h4>
                
                    <h5 class="sidebar-profile-bio"><p>纸上得来终觉浅  绝知此事要躬行</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/ "
                            
                            title="Home"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-tags"
                            
                            title="Tags"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-tags" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Tags</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-archives"
                            
                            title="Archives"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Archives</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link open-algolia-search"
                             href="#search"
                            
                            title="Search"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-search" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Search</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="#about"
                            
                            title="About"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-question" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">About</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://github.com/binhandev" target="_blank" rel="noopener" title="GitHub">
                    
                        <i class="sidebar-button-icon fa fa-lg fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://weibo.com/u/3172823713" target="_blank" rel="noopener" title="Weibo">
                    
                        <i class="sidebar-button-icon fa fa-lg fa-weibo" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Weibo</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/atom.xml"
                            
                            title="RSS"
                        >
                    
                        <i class="sidebar-button-icon fa fa-lg fa-rss" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">RSS</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="4"
                 class="
                        hasCoverMetaIn
                        ">
                
<article class="post">
    
    
        <div class="post-header main-content-wrap text-left">
    
        <h1 class="post-title">
            第一个爬虫-爬取糗百热门段子并存储在 MySQL 数据库中
        </h1>
    
    
        <div class="post-meta">
    <time datetime="2016-01-26T15:20:00+08:00">
	
		    Jan 26, 2016
    	
    </time>
    
</div>

    
</div>

    
    <div class="post-content markdown">
        <div class="main-content-wrap">
            <h3 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h3><p>主要为爬取<a href="http://www.qiushibaike.com/" target="_blank" rel="noopener">糗事百科</a>上热门段子资源，在Terminal下执行命令，参数为项目名。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject qiubai</span><br></pre></td></tr></table></figure>
<h3 id="项目目录结构说明"><a href="#项目目录结构说明" class="headerlink" title="项目目录结构说明"></a>项目目录结构说明</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">qiubai/</span><br><span class="line">	qiubai/</span><br><span class="line">		__init__.py</span><br><span class="line">		items.py	  //项目的items文件</span><br><span class="line">		pipelines.py  	//项目的pipelines文件</span><br><span class="line">		settings	  //项目的设置文件</span><br><span class="line">	scrapy.cfg		  //项目的配置文件</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h3 id="明确目标，定义-item"><a href="#明确目标，定义-item" class="headerlink" title="明确目标，定义 item"></a>明确目标，定义 item</h3><p>在 Scrapy 中，items 是用来加载抓取内容的容器，有点类似 iOS 中的 model 模型，可以理解成类似于 ORM 的映射关系，但是提供了一些额外的保护减少错误。</p>
<p>在qiubai目录下的 items.py 文件，在后面添加我们自己的 class hotItem，包含了头像、昵称、内容、点赞数量及评论数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">hotItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    avatar = scrapy.Field()</span><br><span class="line">    nickname = scrapy.Field()</span><br><span class="line">    content = scrapy.Field()</span><br><span class="line">    like = scrapy.Field()</span><br><span class="line">    commentNum = scrapy.Field()</span><br></pre></td></tr></table></figure>
<h3 id="制作爬虫"><a href="#制作爬虫" class="headerlink" title="制作爬虫"></a>制作爬虫</h3><p>Spider 是用户自己编写的类，用来从一个域（或域组）中抓取信息。<br>他们定义了用于下载的URL列表、跟踪链接的方案、解析网页内容的方式，以此来提取 items。<br>要建立一个 Spider，你必须用 scrapy.spider.BaseSpider 创建一个子类，并确定三个强制的属性：</p>
<ul>
<li>name：爬虫的识别名称，必须是唯一的，在不同的爬虫中你必须定义不同的名字。</li>
<li>start_urls：爬取的URL列表。爬虫从这里开始抓取数据，所以，第一次下载的数据将会从这些 urls 开始。其他子 URL 将会从这些起始URL中继承性生成。</li>
<li>parse()：解析的方法，调用的时候传入从每一个 URL 传回的 Response 对象作为唯一参数，负责解析并匹配抓取的数据(解析为 item )，跟踪更多的 URL。</li>
</ul>
<p>接下来定义 Spider，在项目的 /qiubai/spoders 目录下，并设置了 spider 的名字、爬虫的约束范围，及网页文件进行存储</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">qiubaiSpider</span><span class="params">(scrapy.spiders.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"hot"</span></span><br><span class="line">    allowed_domains = [<span class="string">"qiushibaike.com/"</span>]</span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">"http://www.qiushibaike.com/hot/page/1"</span>,</span><br><span class="line">        <span class="string">"http://www.qiushibaike.com/hot/page/2"</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        filename = response.url.split(<span class="string">"/"</span>)[<span class="number">-1</span>]</span><br><span class="line">        print(filename)</span><br><span class="line">        <span class="keyword">with</span> open(filename, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br></pre></td></tr></table></figure>
<h3 id="爬"><a href="#爬" class="headerlink" title="爬"></a>爬</h3><p>执行爬虫文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl hot</span><br></pre></td></tr></table></figure>
<p>我这里遇到了下面的的问题，导致抓取失败。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2016-01-07 17:24:03 [scrapy] DEBUG: Gave up retrying &lt;GET http://www.qiushibaike.com/hot/page/1&gt; (failed 3 times): [&lt;twisted.python.failure.Failure &lt;class &apos;twisted.internet.error.ConnectionDone&apos;&gt;&gt;]</span><br><span class="line">2016-01-07 17:24:03 [scrapy] ERROR: Error downloading &lt;GET http://www.qiushibaike.com/hot/page/2&gt;: [&lt;twisted.python.failure.Failure &lt;class &apos;twisted.internet.error.ConnectionDone&apos;&gt;&gt;]</span><br></pre></td></tr></table></figure>
<p>其实之前是爬的<a href="http://blog.sina.com.cn/s/articlelist_1191258123_0_1.html" target="_blank" rel="noopener">韩寒的新浪博客</a>，并且成功爬了下来。替换成<a href="http://www.qiushibaike.com/" target="_blank" rel="noopener">糗百</a>后才才出现了上面的错误，所以我猜想是不是糗百对user-agent进行了限制，所以开始为scrapy爬虫添加随机UA：</p>
<p>1、在settings.py中添加以下代码，注意修改对应自己的项目名称</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DOWNLOADER_MIDDLEWARES = </span><br><span class="line">&#123;</span><br><span class="line">	<span class="string">'qiubai.random_user_agent.RandomUserAgentMiddleware'</span>: <span class="number">400</span>,</span><br><span class="line">	<span class="string">'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'</span>: <span class="keyword">None</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment">#-*-coding:utf-8-*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> scrapy.downloadermiddlewares.useragent <span class="keyword">import</span> UserAgentMiddleware</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomUserAgentMiddleware</span><span class="params">(UserAgentMiddleware)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, user_agent=<span class="string">''</span>)</span>:</span></span><br><span class="line">        self.user_agent = user_agent</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        <span class="comment">#这句话用于随机选择user-agent</span></span><br><span class="line">        ua = random.choice(self.user_agent_list)</span><br><span class="line">        <span class="keyword">if</span> ua:</span><br><span class="line">            request.headers.setdefault(<span class="string">'User-Agent'</span>, ua)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#the default user_agent_list composes chrome,I E,firefox,Mozilla,opera,netscape</span></span><br><span class="line">    <span class="comment">#for more user agent strings,you can find it in http://www.useragentstring.com/pages/useragentstring.php</span></span><br><span class="line">    user_agent_list = [\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"</span>\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11"</span>,\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6"</span>,\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6"</span>,\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1"</span>,\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5"</span>,\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5"</span>,\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_0) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3"</span>,\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3"</span>,\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3"</span>,\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3"</span>,\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 (KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3"</span>,\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"</span>,\</span><br><span class="line">        <span class="string">"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24"</span></span><br><span class="line">       ]</span><br></pre></td></tr></table></figure>
<p>添加完成之后，再次执行就OK了。可以在项目根目录下看到1和2两个文件，其实里面的内容是html源代码，当然这仅仅是演示爬取的过程，接下来就是对源码进行解析。</p>
<p>以上这个过程主要是我们将使用创建的爬虫 hot，把 start_urls 里指定的每个URL创建了一个 scrapy.http.Request 对象 ，并将爬虫的 parse 方法指定为回调函数，在这里我们仅仅进行了保存操作。然后，这些 Request 被调度并执行，之后通过 parse() 方法返回 scrapy.http.Response 对象，并反馈给爬虫。</p>
<h3 id="取"><a href="#取" class="headerlink" title="取"></a>取</h3><p>在基础的爬虫里，这一步可以用正则表达式来抓。在 Scrapy 里，使用一种叫做 XPath selectors的机制，它基于 XPath 表达式。如果你想了解更多 selectors 和其他机制你可以查阅资料：<a href="http://scrapy-chs.readthedocs.org/zh_CN/latest/topics/selectors.html" target="_blank" rel="noopener">选择器(Selectors)</a></p>
<h3 id="简单的罗列一下有用的xpath路径表达式："><a href="#简单的罗列一下有用的xpath路径表达式：" class="headerlink" title="简单的罗列一下有用的xpath路径表达式："></a>简单的罗列一下有用的xpath路径表达式：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">    表达式	      描述</span><br><span class="line">nodename	选取此节点的所有子节点。</span><br><span class="line">	/			从根节点选取。</span><br><span class="line">	// 			从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置。</span><br><span class="line">	.			选取当前节点。</span><br><span class="line">	..			选取当前节点的父节点。</span><br><span class="line">	@			选取属性。</span><br></pre></td></tr></table></figure>
<h4 id="下面是一些-XPath-表达式的例子和他们的含义："><a href="#下面是一些-XPath-表达式的例子和他们的含义：" class="headerlink" title="下面是一些 XPath 表达式的例子和他们的含义："></a>下面是一些 XPath 表达式的例子和他们的含义：</h4><ul>
<li>//div[@class=”stats”]: 选择所有包含 class=”stats” 属性的div 标签元素</li>
<li>//td: 选择所有 <td> 元素</td></li>
<li>/title/text(): 选择前面提到的<title> 元素下面的文本内容</title></li>
</ul>
<p>接下来我们将对应的源码标签解析，并将对象保存在 items 列表中，对象保存段子的作者昵称头像等内容，我们主要解析的就是下面这段内容：</p>
<p><img src="/assets/blogImg/qiubai_1.png" alt="Alt text"></p>
<p>修改我们的Spider中的解析逻辑：</p>
<pre><code class="python"><span class="keyword">import</span> scrapy
<span class="keyword">from</span> scrapy.selector <span class="keyword">import</span> Selector  
<span class="keyword">from</span> qiubai.items <span class="keyword">import</span> hotItem

<span class="class"><span class="keyword">class</span> <span class="title">qiubaiSpider</span><span class="params">(scrapy.spiders.Spider)</span>:</span>
    name = <span class="string">"hot"</span>
    allowed_domains = [<span class="string">"qiushibaike.com/"</span>]
    start_urls = [
        <span class="string">"http://www.qiushibaike.com/hot/page/1"</span>,
        <span class="string">"http://www.qiushibaike.com/hot/page/2"</span>
    ]

    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span>
        sel = Selector(response) 
        sites = sel.xpath(<span class="string">'//div[@class="article block untagged mb15"]'</span>)
        items = []
        <span class="keyword">for</span> site <span class="keyword">in</span> sites:
            item = hotItem()
            userSites = site.xpath(<span class="string">'div[@class="author clearfix"]//a'</span>)
            <span class="comment"># 有些时候此标签并不一定存在，需要进行判断</span>
            <span class="keyword">if</span> userSites:
                item[<span class="string">"avatar"</span>] = userSites[<span class="number">0</span>].xpath(<span class="string">'img/@src'</span>).extract()
                item[<span class="string">"nickname"</span>] = userSites[<span class="number">1</span>].xpath(<span class="string">'h2/text()'</span>).extract()
            item[<span class="string">"content"</span>] = site.xpath(<span class="string">'div[@class="content"]/text()'</span>).extract()
            num = site.xpath(<span class="string">'div[@class="stats"]//i'</span>)
            item[<span class="string">"like"</span>] = num[<span class="number">0</span>].xpath(<span class="string">"text()"</span>).extract()
            item[<span class="string">"commentNum"</span>] = num[<span class="number">1</span>].xpath(<span class="string">"text()"</span>).extract()
            items.append(item)
        <span class="keyword">return</span> items
</code></pre>
<h2 id="存储爬取的内容"><a href="#存储爬取的内容" class="headerlink" title="存储爬取的内容"></a>存储爬取的内容</h2><p>保存信息的最简单的方法是通过 <a href="http://scrapy-chs.readthedocs.org/zh_CN/latest/topics/feed-exports.html" target="_blank" rel="noopener">Feed exports</a>，主要有四种数据格式：JSON，JSON lines，CSV，XML。<br>我们将结果用最常用的 JSON 导出，命令如下：</p>
<p>-o 后面是导出文件名，-t 后面是导出类型。</p>
<pre><code>scrapy crawl hot -o items.json -t json
</code></pre><p>此时就可以在项目跟目录下看到 items.json 文件，可以使用文本编辑器查看了。当然我们更多的时候还是希望保存到 <a href="http://www.mysql.com/" target="_blank" rel="noopener">MySQL</a>中便于使用，这时候就需要使用到 pipelines.py 文件了。</p>
<p>当然还需要修改 setting.py 这个文件：将下面这句话加进去</p>
<pre><code>ITEM_PIPELINES=[&apos;fjsen.pipelines.QiubaiPipeline&apos;]
</code></pre><p>并且修改在 pipelines.py 文件，修改对应的数据库账户密码，建议制定为 utf8 编码，否则会出现乱码。并且推荐使用这种方法进行数据插入，写 sql 语句出错太难调了。</p>
<pre><code class="python"><span class="keyword">from</span> scrapy <span class="keyword">import</span> log
<span class="keyword">from</span> twisted.enterprise <span class="keyword">import</span> adbapi
<span class="keyword">import</span> MySQLdb
<span class="keyword">import</span> MySQLdb.cursors

<span class="class"><span class="keyword">class</span> <span class="title">QiubaiPipeline</span><span class="params">(object)</span>:</span>

    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span>
        self.dbpool = adbapi.ConnectionPool(<span class="string">'MySQLdb'</span>, db=<span class="string">'qiubaiDB'</span>,
                user=<span class="string">'root'</span>, passwd=<span class="string">'111111'</span>, cursorclass = MySQLdb.cursors.DictCursor,
                charset=<span class="string">'utf8'</span>, use_unicode=<span class="keyword">True</span>)

    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span>
        <span class="comment"># run db query in thread pool</span>
        query = self.dbpool.runInteraction(self._conditional_insert, item)
        query.addErrback(self.handle_error)
        <span class="keyword">return</span> item

    <span class="function"><span class="keyword">def</span> <span class="title">_conditional_insert</span><span class="params">(self, tx, item)</span>:</span>
        <span class="comment"># create record if doesn't exist.</span>
        <span class="comment"># all this block run on it's own thread</span>
        isExist =tx.execute(<span class="string">'select *from information_schema.tables where table_name = "hot"'</span>)
        <span class="keyword">if</span> isExist:
            sql = <span class="string">"INSERT INTO hot(hot_avatar, hot_nickname, hot_content, hot_like, hot_commentNum) VALUES (%s, %s, %s, %s, %s)"</span>
            avatar = item[<span class="string">"avatar"</span>]
            param = <span class="string">""</span>
            <span class="comment"># 需要判断头像昵称是否真的存在，当然这个判断条件写的比较简单</span>
            <span class="keyword">if</span> avatar:
                param = (item[<span class="string">'avatar'</span>][<span class="number">0</span>], item[<span class="string">"nickname"</span>][<span class="number">0</span>], item[<span class="string">'content'</span>][<span class="number">0</span>], int(item[<span class="string">'like'</span>][<span class="number">0</span>]), int(item[<span class="string">'commentNum'</span>][<span class="number">0</span>]))
            <span class="keyword">else</span>:
                param = (<span class="string">""</span>, <span class="string">""</span>, item[<span class="string">'content'</span>][<span class="number">0</span>], int(item[<span class="string">'like'</span>][<span class="number">0</span>]), int(item[<span class="string">'commentNum'</span>][<span class="number">0</span>]))
            tx.execute(sql, param)
        <span class="keyword">else</span>:
            <span class="comment"># 如果表不存在则创建</span>
            tx.execute(<span class="string">'create table hot(hot_id INT AUTO_INCREMENT PRIMARY KEY, hot_avatar VARCHAR(100) , hot_nickname VARCHAR(100) , hot_content text NOT NULL, hot_like INT NOT NULL,hot_commentNum INT NOT NULL) DEFAULT CHARSET=utf8'</span>)

    <span class="function"><span class="keyword">def</span> <span class="title">handle_error</span><span class="params">(self, e)</span>:</span>
        log.err(e)
</code></pre>
<p>接着，执行爬虫命令后查看数据库就可以了，在此之前确保你的 <a href="http://www.mysql.com/" target="_blank" rel="noopener">MySQL</a> 服务是启动的：</p>
<p><img src="/assets/blogImg/qiubai_2.png" alt="Alt text"></p>

            

        </div>
    </div>
    <div id="post-footer" class="post-footer main-content-wrap">
        
            <div class="post-footer-tags">
                <span class="text-color-light text-small">TAGGED IN</span><br/>
                
    <a class="tag tag--primary tag--small t-link" href="/tags/Python/">Python</a> <a class="tag tag--primary tag--small t-link" href="/tags/Scrapy/">Scrapy</a>

            </div>
        
        
            <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2016/01/27/初识Django搭建网站/" data-tooltip="初识 django 搭建网站" aria-label="PREVIOUS: 初识 django 搭建网站">
                
                    <i class="fa fa-angle-left" aria-hidden="true"></i>
                    <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                </a>
            </li>
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2016/01/06/安装爬虫框架Scrapy遇到的问题及解决方法/" data-tooltip="安装爬虫框架 Scrapy 遇到的问题及解决方法" aria-label="NEXT: 安装爬虫框架 Scrapy 遇到的问题及解决方法">
                
                    <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                    <i class="fa fa-angle-right" aria-hidden="true"></i>
                </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="Share this post">
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://binhandev.github.io/2016/01/26/第一个爬虫-爬取糗百热门段子并存储在MySQL数据库中/" title="Share on Weibo">
                    <i class="fa fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://binhandev.github.io/2016/01/26/第一个爬虫-爬取糗百热门段子并存储在MySQL数据库中/" title="Share on Twitter">
                    <i class="fa fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://binhandev.github.io/2016/01/26/第一个爬虫-爬取糗百热门段子并存储在MySQL数据库中/" title="Share on Facebook">
                    <i class="fa fa-facebook-official" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a class="post-action-btn btn btn--default" href="#disqus_thread">
                        <i class="fa fa-comment-o"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


        
        
            
                <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
            
        
    </div>
</article>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2018 Bin Han. All Rights Reserved.
    </span>
</footer>

            </div>
            
                <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
                    <div class="post-actions-wrap">
    <nav>
        <ul class="post-actions post-action-nav">
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2016/01/27/初识Django搭建网站/" data-tooltip="初识 django 搭建网站" aria-label="PREVIOUS: 初识 django 搭建网站">
                
                    <i class="fa fa-angle-left" aria-hidden="true"></i>
                    <span class="hide-xs hide-sm text-small icon-ml">PREVIOUS</span>
                </a>
            </li>
            <li class="post-action">
                
                    
                    <a class="post-action-btn btn btn--default tooltip--top" href="/2016/01/06/安装爬虫框架Scrapy遇到的问题及解决方法/" data-tooltip="安装爬虫框架 Scrapy 遇到的问题及解决方法" aria-label="NEXT: 安装爬虫框架 Scrapy 遇到的问题及解决方法">
                
                    <span class="hide-xs hide-sm text-small icon-mr">NEXT</span>
                    <i class="fa fa-angle-right" aria-hidden="true"></i>
                </a>
            </li>
        </ul>
    </nav>
    <ul class="post-actions post-action-share">
        <li class="post-action hide-lg hide-md hide-sm">
            <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="Share this post">
                <i class="fa fa-share-alt" aria-hidden="true"></i>
            </a>
        </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://binhandev.github.io/2016/01/26/第一个爬虫-爬取糗百热门段子并存储在MySQL数据库中/" title="Share on Weibo">
                    <i class="fa fa-weibo" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://binhandev.github.io/2016/01/26/第一个爬虫-爬取糗百热门段子并存储在MySQL数据库中/" title="Share on Twitter">
                    <i class="fa fa-twitter" aria-hidden="true"></i>
                </a>
            </li>
        
            
            
            <li class="post-action hide-xs">
                <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://binhandev.github.io/2016/01/26/第一个爬虫-爬取糗百热门段子并存储在MySQL数据库中/" title="Share on Facebook">
                    <i class="fa fa-facebook-official" aria-hidden="true"></i>
                </a>
            </li>
        
        
            
                <li class="post-action">
                    <a class="post-action-btn btn btn--default" href="#disqus_thread">
                        <i class="fa fa-comment-o"></i>
                    </a>
                </li>
            
        
        <li class="post-action">
            
                <a class="post-action-btn btn btn--default" href="#" aria-label="Back to top">
            
                <i class="fa fa-list" aria-hidden="true"></i>
            </a>
        </li>
    </ul>
</div>


                </div>
                <div id="share-options-bar" class="share-options-bar" data-behavior="4">
    <i id="btn-close-shareoptions" class="fa fa-close"></i>
    <ul class="share-options">
        
            
            
            <li class="share-option">
                <a class="share-option-btn" target="new" href="http://service.weibo.com/share/share.php?&amp;title=https://binhandev.github.io/2016/01/26/第一个爬虫-爬取糗百热门段子并存储在MySQL数据库中/">
                    <i class="fa fa-weibo" aria-hidden="true"></i><span>Share on Weibo</span>
                </a>
            </li>
        
            
            
            <li class="share-option">
                <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=https://binhandev.github.io/2016/01/26/第一个爬虫-爬取糗百热门段子并存储在MySQL数据库中/">
                    <i class="fa fa-twitter" aria-hidden="true"></i><span>Share on Twitter</span>
                </a>
            </li>
        
            
            
            <li class="share-option">
                <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=https://binhandev.github.io/2016/01/26/第一个爬虫-爬取糗百热门段子并存储在MySQL数据库中/">
                    <i class="fa fa-facebook-official" aria-hidden="true"></i><span>Share on Facebook</span>
                </a>
            </li>
        
    </ul>
</div>

            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-remove"></i>
        </div>
        
            <img id="about-card-picture" src="https://ooo.0o0.ooo/2017/07/02/595891293dadc.png" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">Bin Han</h4>
        
            <div id="about-card-bio"><p>纸上得来终觉浅  绝知此事要躬行</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>Software Engineer</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker"></i>
                <br/>
                Hangzhou China
            </div>
        
    </div>
</div>

        
            <div id="algolia-search-modal" class="modal-container">
    <div class="modal">
        <div class="modal-header">
            <span class="close-button"><i class="fa fa-close"></i></span>
            <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
                <span class="searchby-algolia-text text-color-light text-small">by</span>
                <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
            </a>
            <i class="search-icon fa fa-search"></i>
            <form id="algolia-search-form">
                <input type="text" id="algolia-search-input" name="search"
                    class="form-control input--large search-input" placeholder="Search "
                    />
            </form>
        </div>
        <div class="modal-body">
            <div class="no-result text-color-light text-center">no post found</div>
            <div class="results">
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://binhandev.github.io/2015/02/17/一个有爱的404页面/">
                            <h3 class="media-heading">一个有爱的404页面</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    Feb 17, 2015
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"><p>在支付宝的爱心支付和<a href="http://bbs.ngacn.cc/" target="_blank" rel="noopener">恩基爱</a>看到一些捐助活动偶尔也会献些爱心，当看到腾讯的这个<a href="http://www.qq.com/404/" target="_blank" rel="noopener">公益 404 页面</a>真是喜欢的不得了，更重要的在 <a href="https://github.com/hexojs/hexo" target="_blank" rel="noopener">hexo</a> 中接入也很简单，当然从某种意义上并不希望经常看到它。</p>
<ul>
<li>在项目根目录source文件夹下直接创建404.html页面</li>
<li>编辑下面html代码，如果定制超链接，修改“homePageUrl”、“homePageName”两个参数即可。</li>
<li>一定要设置layout:false(还有三个短横线)，不然会被hexo解析。</li>
</ul>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">layout: false</span><br><span class="line">---</span><br><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">"en"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">"UTF-8"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>宝贝，公益404带你们回家<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">"http://www.qq.com/404/search_children.js"</span> <span class="attr">charset</span>=<span class="string">"utf-8"</span> <span class="attr">homePageUrl</span>=<span class="string">"http://yoursite.com/yourPage.html"</span> <span class="attr">homePageName</span>=<span class="string">"回到我的主页"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://binhandev.github.io/2015/04/10/对AFNetworking的链式二次封装/">
                            <h3 class="media-heading">对 AFNetworking 的链式二次封装</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    Apr 10, 2015
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"><p>之前在使用 <a href="https://github.com/AFNetworking/AFNetworking" target="_blank" rel="noopener">AFNetworking</a>都会进行二次封装便于开发使用，但是通常的结构是一种集中式的封装，如下：</p>
<figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- (<span class="keyword">void</span>)asyncWithQueryString:(<span class="built_in">NSString</span> *)query params:(<span class="built_in">NSDictionary</span> *)params </span><br><span class="line"> requestType:(RequestType)requestType </span><br><span class="line"> completionHandler:(<span class="keyword">void</span> (^)(<span class="built_in">NSDictionary</span> *result, <span class="built_in">NSError</span> *error))handler；</span><br></pre></td></tr></table></figure>
<p>这种结构的弊端在于，每次调用的时候都需要传递所有的参数，而即使没有参数也需要传递 nil 值站位，尤其如果一开始没有封装好导致后期要在方法里面添加一个参数，那么我们所有调用此方法的地方都需要进行修改，虽然这种可能性很小。所以后来采用了链式结构进行了封装。使用这种方法主要是借鉴了IOS中的布局适配框架 <a href="https://github.com/SnapKit/Masonry" target="_blank" rel="noopener">Masonry</a>，关于链式编程更多的了解可以参考：</p>
<ul>
<li><a href="https://github.com/Wzxhaha/WZXProgrammingIdeas" target="_blank" rel="noopener">https://github.com/Wzxhaha/WZXProgrammingIdeas</a></li>
<li><a href="http://www.ithao123.cn/content-1780874.html" target="_blank" rel="noopener">http://www.ithao123.cn/content-1780874.html</a></li>
</ul></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://binhandev.github.io/2015/04/12/为AFNetWorking添加接口缓存/">
                            <h3 class="media-heading">为 AFNetWorking 添加接口数据缓存</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    Apr 12, 2015
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"><p>NSURLSession 是iOS7之后对 NSURLConnection 更进一步的优化封装，可通过 NSURLSessionConfiguration 对其进行初始化设置，其中 requestCachePolicy 属性设置就是配置获取得到 NSURLResponse 之后的缓存策略：</p></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://binhandev.github.io/2015/05/17/UIBezierPath配合CAShapeLayer画一些有趣的图形/">
                            <h3 class="media-heading">UIBezierPath 配合 CAShapeLayer 画一些有趣的图形</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    May 17, 2015
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"><p>CAShapeLayer是CALayer的子类，但是比CALayer更灵活，配合一个神奇的属性path用这个属性配合上 UIBezierPath 这个类就可以达到超神的效果。</p>
<h3 id="玩一下-UIBezierPath"><a href="#玩一下-UIBezierPath" class="headerlink" title="玩一下 UIBezierPath"></a>玩一下 UIBezierPath</h3><p>UIBezierPath 顾名思义，这是用贝塞尔曲线的方式来构建一段弧线，你可以用任意条弧线来组成你想要的形状，它包含起始点、终点、及控制点三个参数。如下图红色矩形范围内的白色背景，最上面就是一条有弧度的曲线。</p></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://binhandev.github.io/2015/08/05/链式创建UILabel和UIButton/">
                            <h3 class="media-heading">链式创建 UILabel 和 UIButton</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    Aug 5, 2015
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"><p>其实最早接触链式编程是使用 <a href="https://github.com/SnapKit/Masonry" target="_blank" rel="noopener">Masonry</a> 框架的时候，对于之前大部分写集中式编码的人而言会觉得眼前一亮，当所有的操作通过点号(.)符号链接起来时候之后，代码的可读性大大的增强了。所以在之前就使用这种方式对 <a href="https://github.com/AFNetworking/AFNetworking" target="_blank" rel="noopener">AFNetworking</a> 进行了二次封装，<a href="http://binhan1029.github.io/2015/07/11/%E5%AF%B9AFNetworking%E7%9A%84%E9%93%BE%E5%BC%8F%E4%BA%8C%E6%AC%A1%E5%B0%81%E8%A3%85/" target="_blank" rel="noopener">链接地址</a>。</p></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://binhandev.github.io/2015/08/15/封装AVPlayer-包含触摸滑动快进-快退-调节音量-及相关注意点/">
                            <h3 class="media-heading">封装 AVPlayer (包含触摸滑动快进/快退 调节音量)及相关注意点</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    Aug 15, 2015
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"><p>在iOS视频开发中，传统的方案可以直接使用系统的 MPMoviePlayerController 既可以直接将系统的播放页面掉出来，更贴心的为我们添加了控制条，全屏放大及暂停按钮。但是实际中我们可以需要针对播放器做更多的自定义设置，继而更多的是会采用 AVPlayer，因为 AVPlayer 提供了更为强大的功能，虽然在使用的过程会比较麻烦，但是确实能为我们的 app 提供更好的视频播放体验提供前提。</p></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://binhandev.github.io/2015/11/04/UIKit的性能优化/">
                            <h3 class="media-heading">UIKit 的性能优化</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    Nov 4, 2015
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"><p>主要为阅读一些博客和书籍，对一些 UIKit 方便的性能优化的一些知识点进行了整理</p>
<h3 id="尽量避免图层的混合"><a href="#尽量避免图层的混合" class="headerlink" title="尽量避免图层的混合"></a>尽量避免图层的混合</h3><ul>
<li>避免使用控件的 opaque 属性将其透明，当然默认的情况下 UIVie 的 opaque 属性就是 true，同时尽量将UIView的背景颜色设置与其父控件相同且不是透明的</li>
<li>没有特殊情况下不要设置控件的 alpha 值降低透明度</li>
<li>使用 UIImage 尽量使用没有带 alpha 通道图片</li>
</ul>
<h4 id="图层的混合"><a href="#图层的混合" class="headerlink" title="图层的混合"></a>图层的混合</h4><p>首先对于像素点，屏幕上的每一个点就是一个像素，像素有R/G/B三种颜色构成，某些时候还要有 alpha 值。</p>
<p>举个栗子，我们将两个图层混合，上层的是蓝色（R=0/G=0/B=1）,设置其透明度为50%，下层是红色（R=1/G=0/B=0）,那么最终我们看到的效果将是紫色（R=0.5/G=0/B=0.5）,这种颜色的混合，尤其上层的图层有透明度的时候，会小号一定的GPU资源，想避免这种情况，尽量直接将上层的图层透明度设置为100%，这样GPU就会忽略下面的所有图层，避免了过多不要的运算。</p></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://binhandev.github.io/2015/12/03/JSPatch使用小结/">
                            <h3 class="media-heading">JSPatch 使用小结</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    Dec 3, 2015
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"><p>众所周知，iOS 应用审核机制，所以当我们的线上应用面对突如起来的 bug 的时候会显得很手足无措，有时候仅仅可能就是添加一两行代码解决这个问题却要因为审核等待一周或者美国人过节就会有甚至更长的审核周期。所以hoxfix热修复的作用简直就是掉炸天的功能啊。而 JSPatch 就是这样一个极小的轻量级框架，它可以使用 JavaScript 调用任何 Objective-C 的原生接口，替换任意 Objective-C 原生方法。目前主要用于下发 JS 脚本替换原生 Objective-C 代码，实时修复线上 bug。</p></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://binhandev.github.io/2015/12/25/Mac下的Python环境搭建及MySQL-python模块安装/">
                            <h3 class="media-heading">Mac 下的 Python 环境搭建及 MySQL-python 模块安装</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    Dec 25, 2015
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"><h3 id="关于环境"><a href="#关于环境" class="headerlink" title="关于环境"></a>关于环境</h3><p><strong>MAC OS</strong> :10.10</p>
<p><strong>PyCharm</strong> :推荐使用，最开始使用的是 Sublime Text 加终端的方式，但是来回切换实在太繁琐，后来切换到了 PyCharm 下，好的 IDE 真是会使效率事半功倍，更重要还提供了一些很好用的功能用于<a href="https://www.djangoproject.com/" target="_blank" rel="noopener">Django</a>框架开发。</p>
<h3 id="安装-MySQL"><a href="#安装-MySQL" class="headerlink" title="安装 MySQL"></a>安装 MySQL</h3><p>由于之前一直做移动开发，并没有真正使用过 MySQL，而 MySQL 数据库在第一次安装后出现了各种莫名其妙的问题，无论是使用系统偏好设置启动，还是终端启动服务均失败，总是出现各种 <a name="fenced-code-block">permission failed或Can’t connect to local MySQL server through socket ‘/tmp/mysql.sock’</a>等问题，各种方法使用后无解还是尝试重新安装。MySQL<a href="http://dev.mysql.com/downloads/mysql/" target="_blank" rel="noopener">下载地址</a>，一定要选择对应的系统版本及位数。</p>
<p>重新安装前一定要将原本机器上的MySQL删除干净，建议使用终端方法进行删除，<font color="red">注意安装完成后会弹出提示，提示中 password 就是 MySQL 的 root 密码</font>：</p></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
                <div class="media">
                    
                    <div class="media-body">
                        <a class="link-unstyled" href="https://binhandev.github.io/2015/12/31/过去的2015/">
                            <h3 class="media-heading">过去的2015</h3>
                        </a>
                        <span class="media-meta">
                            <span class="media-date text-small">
                                
                                    Dec 31, 2015
                                
                            </span>
                        </span>
                        <div class="media-content hide-xs font-merryweather"></div>
                    </div>
                    <div style="clear:both;"></div>
                    <hr>
                </div>
                
            </div>
        </div>
        <div class="modal-footer">
            <p class="results-count text-medium"
                data-message-zero="no post found"
                data-message-one="1 post found"
                data-message-other="{n} posts found">
                24 posts found
            </p>
        </div>
    </div>
</div>

        
        
<div id="cover" style="background-image:url('https://ooo.0o0.ooo/2017/07/02/5958919e5e7c2.jpg');"></div>
        <!--SCRIPTS-->
<script src="/assets/js/script-yhuo2grt8r7qkqumzgjoglkfbicl1thukjgmla6jopu56zpcowfedi5zjcor.min.js"></script>
<!--SCRIPTS END-->

    
        <script>
             var disqus_config = function () {
                 this.page.url = 'https://binhandev.github.io/2016/01/26/第一个爬虫-爬取糗百热门段子并存储在MySQL数据库中/';
                 
                    this.page.identifier = '2016/01/26/第一个爬虫-爬取糗百热门段子并存储在MySQL数据库中/';
                 
             };
            (function() {
                var d = document, s = d.createElement('script');
                var disqus_shortname = 'http-binhandev-github-io';
                s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

                s.setAttribute('data-timestamp', +new Date());
                (d.head || d.body).appendChild(s);
            })();
        </script>
    


    <script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.14.1/moment-with-locales.min.js"></script>
    <script src="//cdn.jsdelivr.net/algoliasearch/3/algoliasearch.min.js"></script>
    <script>
        var algoliaClient = algoliasearch('8D50WOTW8Q', '1b7cf77512c3f6325bde5b552b9894ff');
        var algoliaIndex = algoliaClient.initIndex('tranquilpeak');
    </script>


    </body>
</html>
